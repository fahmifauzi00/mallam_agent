{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Support Agent with Reflection Pattern\n",
    "## Building a Self-Improving Customer Support Agent\n",
    "In this notebook, we'll create a customer support agent that can:\n",
    "- Handle customer inquiries\n",
    "- Reflect on its responses\n",
    "- Improve its communication\n",
    "- Track customer satisfaction\n",
    "- Learn from past interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "mallam_api_key = os.getenv(\"MALLAM_API_KEY\")\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.mesolitica.com\",\n",
    "    api_key=mallam_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create Support Agent Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(message):\n",
    "    \"\"\"Analyze the customer's message for sentiment and urgency\"\"\"\n",
    "    sentiment_prompt = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"Analyze the customer message and return a JSON with:\n",
    "            - sentiment: (positive, neutral, negative)\n",
    "            - urgency: (low, medium, high)\n",
    "            - emotion: (main emotion detected)\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": message\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"mallam-small\",\n",
    "        messages=sentiment_prompt\n",
    "    )\n",
    "    \n",
    "    return json.loads(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_response(message, sentiment_analysis):\n",
    "    \"\"\"Generate an appropriate support response based on the message and sentiment\"\"\"\n",
    "    support_prompt = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"\"\"You are a helpful customer support agent.\n",
    "            Customer sentiment: {sentiment_analysis['sentiment']}\n",
    "            Customer emotion: {sentiment_analysis['emotion']}\n",
    "            Urgency level: {sentiment_analysis['urgency']}\n",
    "            \n",
    "            Adjust your tone and response accordingly.\n",
    "            If the customer is upset, be extra empathetic.\n",
    "            If urgent, provide immediate next steps.\n",
    "            Always be professional and helpful.\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": message\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"mallam-small\",\n",
    "        messages=support_prompt\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflect_on_support_response(original_message, response, sentiment):\n",
    "    \"\"\"Reflect on the support response to ensure quality and empathy\"\"\"\n",
    "    reflection_prompt = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"Analyze this customer support interaction and provide a JSON with:\n",
    "            - tone_appropriate: (yes/no)\n",
    "            - addressed_issue: (yes/no)\n",
    "            - empathy_level: (1-5)\n",
    "            - suggestions: [list of improvements]\n",
    "            - strong_points: [what was done well]\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"\"\"Customer message: {original_message}\n",
    "            Customer sentiment: {sentiment}\n",
    "            Agent response: {response}\"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    reflection = client.chat.completions.create(\n",
    "        model=\"mallam-small\",\n",
    "        messages=reflection_prompt,\n",
    "        max_tokens=1024\n",
    "    )\n",
    "    \n",
    "    return json.loads(reflection.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improve_support_response(original_message, original_response, reflection):\n",
    "    \"\"\"Generate an improved response based on reflection feedback\"\"\"\n",
    "    if reflection['tone_appropriate'] == 'yes' and reflection['addressed_issue'] == 'yes' and reflection['empathy_level'] >= 4:\n",
    "        return original_response\n",
    "    \n",
    "    improvement_prompt = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"\"\"Improve this customer support response.\n",
    "            Focus on these areas: {', '.join(reflection['suggestions'])}\n",
    "            Keep these strong points: {', '.join(reflection['strong_points'])}\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"Original messages: {original_message}\n",
    "            Original response: {original_response}\"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    improved_response = client.chat.completions.create(\n",
    "        model=\"mallam-small\",\n",
    "        messages=improvement_prompt,\n",
    "        max_tokens=512\n",
    "    )\n",
    "    \n",
    "    return improved_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create Main Support Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_support_request(customer_message):\n",
    "    \"\"\"Handle a customer support request with refleection and improvement\"\"\"\n",
    "    # track timing\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    # 1. Analyze sentiment\n",
    "    sentiment = analyze_sentiment(customer_message)\n",
    "    \n",
    "    # 2. Generate initial response\n",
    "    initial_response = support_response(customer_message, sentiment)\n",
    "    \n",
    "    # 3. Reflection\n",
    "    reflection = reflect_on_support_response(\n",
    "        customer_message,\n",
    "        initial_response,\n",
    "        sentiment\n",
    "    )\n",
    "    \n",
    "    # 4. Improve response if needed\n",
    "    final_response = improve_support_response(\n",
    "        customer_message,\n",
    "        initial_response,\n",
    "        reflection\n",
    "    )\n",
    "    \n",
    "    # calaculate response time\n",
    "    response_time = (datetime.now() - start_time).total_seconds()\n",
    "    \n",
    "    return {\n",
    "        \"sentiment_analysis\": sentiment,\n",
    "        \"initial_response\": initial_response,\n",
    "        \"reflection\": reflection,\n",
    "        \"final_response\": final_response,\n",
    "        \"response_time\": response_time\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Test the Support Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test case 1: Frustrated Customer\n",
      "\n",
      "Sentiment: {'sentiment': 'negative', 'urgency': 'high', 'emotion': 'anger'}\n",
      "\n",
      "Initial Response: I'm sorry to hear about your issue with duplicate charges. I understand how frustrating it can be to deal with billing errors, especially when it affects your financial statements. Let's work together to resolve this as quickly as possible.\n",
      "\n",
      "First, could you please provide me with your account number or any other identification details so that I can look up your transaction history? Once I have that information, I'll be able to confirm whether there were indeed two charges made to your account this month.\n",
      "\n",
      "Additionally, it would be helpful if you could specify the dates of these charges and any reference numbers or descriptions associated with them. This information will allow me to trace the transactions more accurately.\n",
      "\n",
      "Once I've gathered the necessary details, I'll investigate the charges on your behalf. My goal is to ensure that everything is in order and that any discrepancies are rectified promptly.\n",
      "\n",
      "If there was an error on our part, we're committed to correcting it and making sure that you aren't charged twice for the same service or product. Your satisfaction is important to us, and we want to restore your confidence in our billing processes.\n",
      "\n",
      "Please know that I'm here to assist you and that resolving this issue is my top priority. I appreciate your patience and understanding as we work towards a solution.\n",
      "\n",
      "**Next Steps:**\n",
      "\n",
      "\n",
      "\n",
      "Reflection: {'tone_appropriate': 'yes', 'addressed_issue': 'yes', 'empathy_level': 4, 'suggestions': ['Include a direct action plan', 'Ensure the response is clear and concise', 'Consider adding more proactive solutions'], 'strong_points': [\"Acknowledged the customer's frustration\", 'Offered assistance to resolve the issue', \"Emphasized the company's commitment to correct errors\"]}\n",
      "\n",
      "Final Response I'm sorry to hear about your issue with duplicate charges. I understand how frustrating it can be to deal with billing errors, especially when it affects your financial statements. Let's work together to resolve this as quickly as possible.\n",
      "\n",
      "First, could you please provide me with your account number or any other identification details so that I can look up your transaction history? Once I have that information, I'll be able to confirm whether there were indeed two charges made to your account this month.\n",
      "\n",
      "Additionally, it would be helpful if you could specify the dates of these charges and any reference numbers or descriptions associated with them. This information will allow me to trace the transactions more accurately.\n",
      "\n",
      "Once I've gathered the necessary details, I'll investigate the charges on your behalf. My goal is to ensure that everything is in order and that any discrepancies are rectified promptly.\n",
      "\n",
      "If there was an error on our part, we're committed to correcting it and making sure that you aren't charged twice for the same service or product. Your satisfaction is important to us, and we want to restore your confidence in our billing processes.\n",
      "\n",
      "Please know that I'm here to assist you and that resolving this issue is my top priority. I appreciate your patience and understanding as we work towards a solution.\n",
      "\n",
      "**Next Steps:**\n",
      "\n",
      "\n",
      "\n",
      "Response Time: 14.931219\n"
     ]
    }
   ],
   "source": [
    "# Test case 1: Frustrated customer with billing issue\n",
    "print(\"Test case 1: Frustrated Customer\")\n",
    "result = handle_support_request(\n",
    "    \"I've been charged twice this month and nobody is helping me! This is ridiculous!\"\n",
    ")\n",
    "print(\"\\nSentiment:\", result[\"sentiment_analysis\"])\n",
    "print(\"\\nInitial Response:\", result[\"initial_response\"])\n",
    "print(\"\\nReflection:\", result[\"reflection\"])\n",
    "print(\"\\nFinal Response\", result[\"final_response\"])\n",
    "print(\"\\nResponse Time:\", result[\"response_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test case 2: Technical support\n",
      "\n",
      "Sentiment: {'sentiment': 'neutral', 'urgency': 'medium', 'emotion': 'frustration'}\n",
      "\n",
      "Initial Response: Of course, I'd be happy to assist you with that. It sounds like you're experiencing some issues logging into your account. Could you please tell me what exactly is happening when you try to log in? Are you getting any error messages or is the login just not responding?\n",
      "\n",
      "Reflection: {'tone_appropriate': 'yes', 'addressed_issue': 'yes', 'empathy_level': 4, 'suggestions': [], 'strong_points': ['The agent is approachable and offers help.', 'They ask for more details to understand the problem better.', 'Agent shows empathy by acknowledging frustration.']}\n",
      "\n",
      "Final Response Of course, I'd be happy to assist you with that. It sounds like you're experiencing some issues logging into your account. Could you please tell me what exactly is happening when you try to log in? Are you getting any error messages or is the login just not responding?\n",
      "\n",
      "Response Time: 6.176486\n"
     ]
    }
   ],
   "source": [
    "# Test case 2: Technical support request\n",
    "print(\"Test case 2: Technical support\")\n",
    "result = handle_support_request(\n",
    "    \"Hi, I'm having trouble logging into my account. Can you help?\"\n",
    ")\n",
    "print(\"\\nSentiment:\", result[\"sentiment_analysis\"])\n",
    "print(\"\\nInitial Response:\", result[\"initial_response\"])\n",
    "print(\"\\nReflection:\", result[\"reflection\"])\n",
    "print(\"\\nFinal Response\", result[\"final_response\"])\n",
    "print(\"\\nResponse Time:\", result[\"response_time\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Track Support Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Support Interaction Metrics:\n",
      "{\n",
      "  \"timestamp\": \"2025-01-09T02:21:01.220185\",\n",
      "  \"response_time\": 13.489313,\n",
      "  \"sentiment\": \"positive\",\n",
      "  \"urgency\": \"low\",\n",
      "  \"empathy_level\": 5,\n",
      "  \"needed_improvement\": false,\n",
      "  \"improvement_areas\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def track_support_interaction(interaction_data):\n",
    "    \"\"\"\n",
    "    Track metrics for this support interaction\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"response_time\": interaction_data[\"response_time\"],\n",
    "        \"sentiment\": interaction_data[\"sentiment_analysis\"][\"sentiment\"],\n",
    "        \"urgency\": interaction_data[\"sentiment_analysis\"][\"urgency\"],\n",
    "        \"empathy_level\": interaction_data[\"reflection\"][\"empathy_level\"],\n",
    "        \"needed_improvement\": interaction_data[\"initial_response\"] != interaction_data[\"final_response\"],\n",
    "        \"improvement_areas\": interaction_data[\"reflection\"][\"suggestions\"]\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Example of tracking metrics\n",
    "result = handle_support_request(\n",
    "    \"I've been a customer for 3 years and love your service, but I found a small bug in the latest update.\"\n",
    ")\n",
    "metrics = track_support_interaction(result)\n",
    "print(\"\\nSupport Interaction Metrics:\")\n",
    "print(json.dumps(metrics, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
